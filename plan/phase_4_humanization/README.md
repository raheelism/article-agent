# Phase 4: Humanization & RAG (Hours 7-8) ‚úÖ COMPLETE

## üéØ Achievement: 0% AI Detection

> Generated articles pass AI detection tools with **0% AI-detected content**, making them indistinguishable from human writing.

## Goal
Implement the final quality layer that transforms AI-generated content into human-like prose through multi-model evaluation and reflexion-based humanization.

## Implementation Steps

### 1. Evaluator Subgraph (`app/graphs/evaluator.py`)
- [x] **Parallel Multi-Model Critique:**
    - Qwen 32B ‚Üí SEO & Structure analysis
    - Kimi K2 ‚Üí Engagement & Tone evaluation
    - Llama 4 Maverick ‚Üí Logic & Accuracy verification
- [x] **Critique Aggregation:** Collect all critiques for the optimizer.
- [x] **Optimizer Node:** GPT-120B synthesizes all feedback and rewrites the draft.
- [x] **Wiring:** Connect critics in parallel, then route to optimizer.

### 2. Humanizer Subgraph (`app/graphs/humanizer.py`)
- [x] **Reflexion Loop Architecture:**
    - Maximum 3 iterations to prevent infinite loops.
    - Early exit when score reaches acceptable threshold.
- [x] **Humanization Critic:**
    - Detects 6 categories of AI artifacts:
        1. **Hedging Language** ("It's important to note", "may potentially")
        2. **Robotic Connectors** ("Furthermore", "Moreover", "In conclusion")
        3. **Nominalization** ("The utilization of" ‚Üí "Using")
        4. **Sensory Vacuum** (Missing sounds, textures, smells)
        5. **AI Vocabulary** (20+ banned words like "delve", "leverage", "robust")
        6. **Uniform Sentence Length** (Lack of burstiness)
    - Scores each category 0-10.
- [x] **Refiner Node:**
    - Example-rich prompts with before/after transformations.
    - Chain of Density technique for compression.
    - Sensory injection for vivid prose.
    - Connector pruning and hedge elimination.

### 3. RAG-Powered Writing (`app/graphs/writer.py`)
- [x] **Embedding Model:** SentenceTransformers (all-MiniLM-L6-v2)
    - Local model support for offline/corporate networks.
    - Auto-download from HuggingFace on first run.
- [x] **Vector Store:** FAISS for fast similarity search.
- [x] **Chunking Strategy:** ~600-1000 tokens per chunk for optimal context.
- [x] **Retrieval:** Top-K relevant chunks per section to avoid rate limits.

### 4. Anti-AI Writing Constraints
- [x] **Banned Words List:** 20+ robotic words automatically avoided.
- [x] **Sentence Burstiness:** Mix of short punchy and longer flowing sentences.
- [x] **Before/After Examples:** Prompts include transformation examples:
    ```
    ‚ùå AI: "It is important to note that remote work offers numerous benefits."
    ‚úÖ Human: "Remote work changed everything. No commute. No dress code. Just results."
    ```

### 5. Integration with Main Graph
- [x] Route from Writer ‚Üí Evaluator ‚Üí Humanizer ‚Üí Finalizer.
- [x] Conditional routing based on humanization score.
- [x] Final article saved to `Generated articles/{Topic}_{Timestamp}.md`.

## Technical Details

### Models Used in Phase 4

| Purpose | Model | Temperature |
|---------|-------|-------------|
| Critique (SEO) | `qwen/qwen3-32b` | 0.1 |
| Critique (Engagement) | `moonshotai/kimi-k2-instruct` | 0.2 |
| Critique (Logic) | `meta-llama/llama-4-maverick-17b-128e-instruct` | 0.1 |
| Optimizer | `openai/gpt-oss-120b` | 0.2 |
| Humanization Critic | `openai/gpt-oss-120b` | 0.1 |
| Refiner | `openai/gpt-oss-120b` | 0.4 |

### Environment Variables
```bash
# Optional: Use local embedding model (for corporate networks with SSL issues)
EMBEDDING_MODEL_PATH=models/all-MiniLM-L6-v2

# Optional: Bypass SSL verification (for corporate proxies)
DISABLE_SSL_VERIFY=true
```

## Success Criteria for Phase 4 ‚úÖ
- Generated articles achieve **0% AI detection** on AI detection tools.
- Multi-model evaluation provides diverse critique perspectives.
- Humanizer successfully removes AI artifacts in ‚â§3 iterations.
- RAG retrieval keeps context within rate limits while maintaining quality.
- Articles are indistinguishable from human-written content.
